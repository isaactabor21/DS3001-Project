{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tytp57fW3fr"
      },
      "source": [
        "# Pre-Analysis Plan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aNIDF3YW3fr"
      },
      "source": [
        "##### Kimberly Liu & Isaac Tabor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Research Question:\n",
        "**What are the most likely March Madness outcome according to our XGBoost model?**"
      ],
      "metadata": {
        "id": "2inec5eIpUH5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFCuM9GqW3fs"
      },
      "source": [
        "## What is an observation in our study?\n",
        "An observation in our study represents a single game from any season within our range. Each observation contains detailed information on both the winning and losing teams, capturing not only the final scores but also a comprehensive breakdown of game statistics. This includes metrics such as the number of points scored, shooting efficiency (field goals, three-pointers, and free throws), rebounds (offensive and defensive), assists, turnovers, steals, blocks, and personal fouls. Additionally, observations incorporate contextual details like game location, overtime periods, and team rankings from various sources. Together, these data points allow us to analyze performance trends and form the foundation for building a predictive model for March Madness outcomes.\n",
        "\n",
        "In addition to our game-level dataset, we've created a second dataframe that aggregates these observations by team for each season. This aggregation provides a season-long summary of a teamâ€™s performance. An observation in this dataset is a season's season-long average statistics.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Are you doing supervised or unsupervised learning? Classification or regression?\n",
        "\n",
        "In our study, we will be doing supervised binary classification to predict probabilities of each matchup because we are predicting whether a team will win or not (Win or Loss). Specifically, we will output the probability score for each class.  It is supervised because we are creating a model trained on labeled data (historical match results with known outcomes)."
      ],
      "metadata": {
        "id": "42L_fQGCdRV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What models or algorithms do you plan to use in your analysis? How?\n",
        "\n",
        "We plan to use XGBRegressor, which is typically used for regression tasks. However, we plan to use the logloss metric, which aligns with the classification nature of our study. So, our outputs will be predicted probabilities of one class (Team A winning), and we can use a threshold of .5 to classify each game into binary classes: Win vs. Lose."
      ],
      "metadata": {
        "id": "gtx_dpFBfzHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How will we know if our approach \"works\"? What does success mean?"
      ],
      "metadata": {
        "id": "pej1YoRLjo9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will measure success by either comparing our results to a \"Chalk\" benchmark. This means, what would our accuracy have been if we had just used the higher seed to predict the outcome of each game in the 2025 NCAA tournament. If our accuracy is higher than chalk, we will consider ourselves \"successful.\" For 1-seed vs. 1-seed matchups, for example, in the Final Four, we will use Win Percentage in the \"Chalk\" benchmark to predict the outcome."
      ],
      "metadata": {
        "id": "_QHQPBz9jscP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What weaknesses do we anticipate being an issue? How will we deal with them if they come up? If our approach fails, what might we learn from this unfortunate outcome?\n",
        "\n",
        "A major weaknesss we anticiapte being an issue is overfitting. XGBoost is an advanced form of gradient boosting, and like other boosting algorithms, it can overfit when too many trees are added or when regularization is not applied properly. If this comes up, we will deal with this by reviewing whether we have an excessive number of boosting rounds, improper regularization, etc. If our approach fails, we might learn that finding the right model complexity balance is crucial. We do not want it to be too complex such that it overfits, but we also do not want it to be too simple that it does not capture meaningful patterns."
      ],
      "metadata": {
        "id": "fjKFx0kSkqhb"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tytp57fW3fr"
      },
      "source": [
        "# Pre-Analysis Plan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aNIDF3YW3fr"
      },
      "source": [
        "##### Kimberly Liu & Isaac Tabor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2inec5eIpUH5"
      },
      "source": [
        "## Research Question:\n",
        "**What are the most likely March Madness outcomes according to our XGBoost model?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFCuM9GqW3fs"
      },
      "source": [
        "## What is an observation in our study?\n",
        "An observation in our study represents a single game from any season within our range. Each observation contains detailed information on both the winning and losing teams, capturing not only the final scores but also a comprehensive breakdown of game statistics. This includes metrics such as the number of points scored, shooting efficiency (field goals, three-pointers, and free throws), rebounds (offensive and defensive), assists, turnovers, steals, blocks, and personal fouls. Additionally, observations incorporate contextual details like game location, overtime periods, and team rankings from various sources. Together, these data points allow us to analyze performance trends and form the foundation for building a predictive model for March Madness outcomes.\n",
        "\n",
        "In addition to our game-level dataset, we've created a second dataframe that aggregates these observations by team for each season. This aggregation provides a season-long summary of a team’s performance. An observation in this dataset is a season's season-long average statistics.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42L_fQGCdRV9"
      },
      "source": [
        "## Are you doing supervised or unsupervised learning? Classification or regression?\n",
        "\n",
        "In our study, we will be doing supervised binary classification to predict probabilities of each matchup because we are predicting whether a team will win or not (Win or Loss). Specifically, we will output the probability score for each class.  It is supervised because we are creating a model trained on labeled data (historical match results with known outcomes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtx_dpFBfzHG"
      },
      "source": [
        "## What models or algorithms do you plan to use in your analysis? How?\n",
        "\n",
        "We plan to use XGBRegressor, which is typically used for regression tasks. However, we plan to use the logloss metric, which aligns with the classification nature of our study. So, our outputs will be predicted probabilities of one class (Team A winning), and we can use a threshold of .5 to classify each game into binary classes: Win vs. Lose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pej1YoRLjo9S"
      },
      "source": [
        "## How will we know if our approach \"works\"? What does success mean?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QHQPBz9jscP"
      },
      "source": [
        "We will measure success by either comparing our results to a \"Chalk\" benchmark. This means, what would our accuracy have been if we had just used the higher seed to predict the outcome of each game in the 2025 NCAA tournament. If our accuracy is higher than chalk, we will consider ourselves \"successful.\" For 1-seed vs. 1-seed matchups, for example, in the Final Four, we will use Win Percentage in the \"Chalk\" benchmark to predict the outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjKFx0kSkqhb"
      },
      "source": [
        "## What weaknesses do we anticipate being an issue? How will we deal with them if they come up? If our approach fails, what might we learn from this unfortunate outcome?\n",
        "\n",
        "A major weaknesss we anticiapte being an issue is overfitting. XGBoost is an advanced form of gradient boosting, and like other boosting algorithms, it can overfit when too many trees are added or when regularization is not applied properly. If this comes up, we will deal with this by reviewing whether we have an excessive number of boosting rounds, improper regularization, etc. If our approach fails, we might learn that finding the right model complexity balance is crucial. We do not want it to be too complex such that it overfits, but we also do not want it to be too simple that it does not capture meaningful patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering \n",
        "\n",
        "In preparation for our predictive modeling task, we are employing a number of feature engineering strategies to better capture the dynamics of NCAA basketball games. At the core of our design is the creation of team-level differentials—by taking the difference between the season-aggregated statistics of each team in a matchup, we aim to capture relative strengths and weaknesses. For example, differences in win percentage, field goal percentage, or average turnovers may be more predictive of outcomes than absolute values alone. These matchup-specific features allow the model to learn from the performance gap between teams rather than raw statistics.\n",
        "\n",
        "We also incorporate seeding information, when available, as a key input. Seeds are encoded numerically, and the difference between team seeds will be used to provide an additional signal to the model. Since seeds are known only after Selection Sunday, they will be included in the final model once the bracket is released. For categorical variables like game location (WLoc) or team conferences (WConf, LConf), we will apply one-hot encoding to prevent the model from inferring any false ordinal relationships.\n",
        "\n",
        "External team rankings such as NET, POM, RPI, USA Today Coaches Poll, and the AP Poll are also included as numeric features. Because many of these are likely to be highly correlated, we plan to inspect multicollinearity using correlation matrices and may apply Principal Component Analysis (PCA) to reduce dimensionality while preserving variance if needed. Finally, numeric features will be scaled appropriately—using standard scaling or min-max normalization—to ensure consistency across different ranges of values, which is especially important for tree-based models to avoid biased splits. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "\n",
        "To evaluate our model’s performance and determine whether our approach is successful, we will rely on a combination of evaluation metrics, visualizations, and benchmarks. Our primary metric will be log loss, which penalizes incorrect probability estimates and rewards confident, correct predictions. This is particularly appropriate since our model outputs a probability score for each game rather than a hard classification. A lower log loss score indicates that the model is well-calibrated and is generating accurate probability distributions.\n",
        "\n",
        "While log loss will guide our model training, we will also report secondary metrics such as accuracy, precision, and recall after converting probability scores into binary outcomes using a 0.5 threshold. A confusion matrix will help us visually assess where the model tends to succeed or fail—whether it consistently mispredicts close matchups or struggles with upsets, for example. Additionally, an ROC curve may be included to visualize the model’s ability to discriminate between winners and losers across all probability thresholds.\n",
        "\n",
        "We will benchmark our model against a “chalk” strategy, which assumes that the higher-seeded team always wins. This serves as a meaningful baseline, especially in the context of March Madness, where early round matchups often favor top seeds. If our model performs better than chalk in terms of accuracy or log loss, we will consider it a success. In cases where seed matchups are equal (such as Final Four games between #1 seeds), we will default to historical win percentage as a tiebreaker in the chalk model.\n",
        "\n",
        "Lastly, to improve transparency and interpretability, we will extract and display feature importance values from the trained XGBoost model. This allows us to understand which features had the greatest impact on the prediction outcome—whether it's a team's win percentage, average rebounds, or seed differential. Combined with visualizations such as ROC curves, confusion matrices, and calibration plots, this approach will help us communicate both the success and limitations of our model clearly."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
